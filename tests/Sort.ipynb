{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdf10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from conllu import parse\n",
    "from nltk import DependencyGraph\n",
    "from ufal.udpipe import Model, Pipeline\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from modeling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b88d6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: Когда будет сессия?\n",
      "Sentiment  : учебная деятельность\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pre_trained_model_ckpt)\n",
    "class_names = ['поступление - перевод', 'общежитие', 'учебная деятельность', 'внеучебная деятельность', 'документы', 'работа', 'финансы']\n",
    "model = SentimentClassifier(len(class_names))\n",
    "model.load_state_dict(torch.load('model/best_model_state.bin'))\n",
    "model = model.to(device)\n",
    "\n",
    "review_text = \"Когда будет сессия?\"\n",
    "encoded_review = tokenizer.encode_plus(review_text, max_length=512, add_special_tokens=True, return_token_type_ids=False, pad_to_max_length=True, return_attention_mask=True,\n",
    "                                       truncation=True, return_tensors='pt')\n",
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask=encoded_review['attention_mask'].to(device)\n",
    "output = model(input_ids, attention_mask)\n",
    "_,prediction = torch.max(output, dim=1)\n",
    "\n",
    "print(f'Review text: {review_text}')\n",
    "print(f'Sentiment  : {class_names[prediction]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34aac93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>tq</th>\n",
       "      <th>ta</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Здраствуйте, если ты уже зачислен на первый ку...</td>\n",
       "      <td>Здравствуйте. Вам необходимо сообщить об этом ...</td>\n",
       "      <td>[30191., 29508., 34394., 90641., 1523.]</td>\n",
       "      <td>[13802., 29526., 38156.]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Здравствуйте! В магистратуре можно ли поменять...</td>\n",
       "      <td>Здравствуйте. По данному вопросу обратитесь по...</td>\n",
       "      <td>[ 7021., 65900., 13552., 13123.]</td>\n",
       "      <td>[ 9168., 77489., 114408.]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Добрый день! Абитуриент МАГ/261 ФЭН.1Мз. По со...</td>\n",
       "      <td>Здравствуйте. Приказ уже был, информация о зач...</td>\n",
       "      <td>[20070., 15887., 47518., 7996., 77599., 24706.]</td>\n",
       "      <td>[81373., 15887., 46486., 1761., 24970., 1984.]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Здравствуйте, как забрать оригинал аттестата, ...</td>\n",
       "      <td>Здравствуйте. Вам необходимо обратиться в прие...</td>\n",
       "      <td>[12834., 40597., 63002., 45633., 22451.]</td>\n",
       "      <td>[13802., 29526., 29549., 31283., 15514., 28707.]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Здравствуйте. Где на сайте можно ознакомиться ...</td>\n",
       "      <td>Здравствуйте. Приказы о зачислении на сайте не...</td>\n",
       "      <td>[ 7021., 43485.]</td>\n",
       "      <td>[54211., 51623.]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47061</th>\n",
       "      <td>Какие программы скидок предлагаются для обуче...</td>\n",
       "      <td>В зависимости от университета, могут быть пре...</td>\n",
       "      <td>[82877., 11520.]</td>\n",
       "      <td>[ 7603., 39892., 1770., 61692., 11267., 11520....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47062</th>\n",
       "      <td>Какова стоимость обучения в университете по м...</td>\n",
       "      <td>Стоимость обучения в университете по медицинс...</td>\n",
       "      <td>[ 53556, 15850, 12201, 106909, 16753]</td>\n",
       "      <td>[19709., 15850.]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47063</th>\n",
       "      <td>Какие дополнительные расходы могут возникнуть...</td>\n",
       "      <td>Дополнительные расходы могут включать в себя ...</td>\n",
       "      <td>[ 7603., 23000., 51172.]</td>\n",
       "      <td>[ 7603., 23000., 35778., 37744.]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47064</th>\n",
       "      <td>Какие программы скидок предлагаются для обуче...</td>\n",
       "      <td>В зависимости от университета, могут быть пре...</td>\n",
       "      <td>[82877., 11520.]</td>\n",
       "      <td>[ 7603., 39892., 1770., 61692., 11267., 11520....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47065</th>\n",
       "      <td>Какова стоимость обучения в университете по ю...</td>\n",
       "      <td>Стоимость обучения в университете по юридичес...</td>\n",
       "      <td>[ 53556, 15850, 12201, 106909, 16753]</td>\n",
       "      <td>[19709., 15850.]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47066 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       q  \\\n",
       "0      Здраствуйте, если ты уже зачислен на первый ку...   \n",
       "1      Здравствуйте! В магистратуре можно ли поменять...   \n",
       "2      Добрый день! Абитуриент МАГ/261 ФЭН.1Мз. По со...   \n",
       "3      Здравствуйте, как забрать оригинал аттестата, ...   \n",
       "4      Здравствуйте. Где на сайте можно ознакомиться ...   \n",
       "...                                                  ...   \n",
       "47061   Какие программы скидок предлагаются для обуче...   \n",
       "47062   Какова стоимость обучения в университете по м...   \n",
       "47063   Какие дополнительные расходы могут возникнуть...   \n",
       "47064   Какие программы скидок предлагаются для обуче...   \n",
       "47065   Какова стоимость обучения в университете по ю...   \n",
       "\n",
       "                                                       a  \\\n",
       "0      Здравствуйте. Вам необходимо сообщить об этом ...   \n",
       "1      Здравствуйте. По данному вопросу обратитесь по...   \n",
       "2      Здравствуйте. Приказ уже был, информация о зач...   \n",
       "3      Здравствуйте. Вам необходимо обратиться в прие...   \n",
       "4      Здравствуйте. Приказы о зачислении на сайте не...   \n",
       "...                                                  ...   \n",
       "47061   В зависимости от университета, могут быть пре...   \n",
       "47062   Стоимость обучения в университете по медицинс...   \n",
       "47063   Дополнительные расходы могут включать в себя ...   \n",
       "47064   В зависимости от университета, могут быть пре...   \n",
       "47065   Стоимость обучения в университете по юридичес...   \n",
       "\n",
       "                                                    tq  \\\n",
       "0              [30191., 29508., 34394., 90641., 1523.]   \n",
       "1                     [ 7021., 65900., 13552., 13123.]   \n",
       "2      [20070., 15887., 47518., 7996., 77599., 24706.]   \n",
       "3             [12834., 40597., 63002., 45633., 22451.]   \n",
       "4                                     [ 7021., 43485.]   \n",
       "...                                                ...   \n",
       "47061                                 [82877., 11520.]   \n",
       "47062            [ 53556, 15850, 12201, 106909, 16753]   \n",
       "47063                         [ 7603., 23000., 51172.]   \n",
       "47064                                 [82877., 11520.]   \n",
       "47065            [ 53556, 15850, 12201, 106909, 16753]   \n",
       "\n",
       "                                                      ta  label  \n",
       "0                               [13802., 29526., 38156.]      0  \n",
       "1                              [ 9168., 77489., 114408.]      0  \n",
       "2         [81373., 15887., 46486., 1761., 24970., 1984.]      0  \n",
       "3       [13802., 29526., 29549., 31283., 15514., 28707.]      0  \n",
       "4                                       [54211., 51623.]      0  \n",
       "...                                                  ...    ...  \n",
       "47061  [ 7603., 39892., 1770., 61692., 11267., 11520....      7  \n",
       "47062                                   [19709., 15850.]      7  \n",
       "47063                   [ 7603., 23000., 35778., 37744.]      7  \n",
       "47064  [ 7603., 39892., 1770., 61692., 11267., 11520....      7  \n",
       "47065                                   [19709., 15850.]      7  \n",
       "\n",
       "[47066 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('make_dataset/08042023_dataset_sort_change_tokenizer_fix.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab4c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "def mySort(s1, s2):\n",
    "  matcher = difflib.SequenceMatcher(None, s1, s2)\n",
    "  return matcher.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac630ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sov(sent):\n",
    "    graph = DependencyGraph(tree_str=sent)\n",
    "    sov = {}\n",
    "    for triple in graph.triples():\n",
    "        if triple:\n",
    "            if triple[0][1] == 'VERB':\n",
    "                sov[triple[0][0]] = {'subj':'','obj':''}\n",
    "    for triple in graph.triples():\n",
    "        if triple:\n",
    "            if triple[1] == 'nsubj':\n",
    "                if triple[0][1] == 'VERB':\n",
    "                    sov[triple[0][0]]['subj']  = triple[2][0]\n",
    "            if 'obj' in triple[1]:\n",
    "                if triple[0][1] == 'VERB':\n",
    "                    sov[triple[0][0]]['obj'] = triple[2][0]\n",
    "    return sov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2138d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load('model/russian-ud-2.0-170801.udpipe')\n",
    "tokenizer = BertTokenizer.from_pretrained(pre_trained_model_ckpt)\n",
    "def tokenText(text):\n",
    "    arrParsed = []\n",
    "    longParsed = ''\n",
    "\n",
    "    sent = str(text)\n",
    "    sent = re.sub(\"\\s\\s+\", ' ', sent)\n",
    "    sent = sent.lower()\n",
    "    sent = sent.strip()\n",
    "    sent = sent.replace(u'\\xa0', u' ')\n",
    "    sentS = re.split(\";|! |\\?|\\. \", sent)\n",
    "    sentS = list(filter(None, sentS))\n",
    "\n",
    "    for nSentS in sentS:\n",
    "        nSentS = re.sub(r'[^\\w\\s]','', nSentS) \n",
    "\n",
    "        pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, Pipeline.DEFAULT)\n",
    "        parsed = pipeline.process(nSentS)\n",
    "\n",
    "        # костыли для dependency graph\n",
    "        parsed = '\\n'.join([line for line in parsed.split('\\n') if not line.startswith('#')])\n",
    "        parsed = parsed.replace('\\troot\\t', '\\tROOT\\t')\n",
    "\n",
    "        if (len(longParsed) < len(parsed)):\n",
    "            longParsed = parsed\n",
    "\n",
    "        arrParsed.append(parsed)\n",
    "    arrParsed = list(filter(None, arrParsed))\n",
    "\n",
    "    arrSov = []\n",
    "    for nArrParsed in arrParsed:\n",
    "        sov = get_sov(nArrParsed)\n",
    "        arrSov.append(sov)\n",
    "\n",
    "    bigSov = arrSov[0]\n",
    "    if (len(arrSov) > 1):\n",
    "        for i in range(1, len(arrSov)):\n",
    "            bigSov = { **bigSov, ** arrSov[i] }\n",
    "\n",
    "    tokenizedA = []\n",
    "    if (bigSov == {}):\n",
    "        arrGraph = []\n",
    "        graph = DependencyGraph(tree_str=longParsed)\n",
    "        for i in range(0, len(list(graph.triples()))):\n",
    "            for j in range(0, len(list(graph.triples())[0])):\n",
    "                if (list(graph.triples())[i][j][1] == 'NOUN'):\n",
    "                    arrGraph.append(list(graph.triples())[i][j][0])\n",
    "        arrGraph = set(arrGraph)\n",
    "        if (len(arrGraph) == 0):\n",
    "            tokenizedA.append('!');\n",
    "        else:\n",
    "            for nArrGraph in arrGraph:\n",
    "                tokenizedA.append(tokenizer.encode(nArrGraph, add_special_tokens=False))\n",
    "            tokenizedA = np.concatenate(tokenizedA, axis=0, out=None, dtype=None, casting=\"same_kind\")\n",
    "    else:\n",
    "        for k, v in bigSov.items(): \n",
    "            tokenizedA.append(tokenizer.encode(k, add_special_tokens=False))\n",
    "            tokenizedA.append(tokenizer.encode(v['subj'], add_special_tokens=False))\n",
    "            tokenizedA.append(tokenizer.encode(v['obj'], add_special_tokens=False))\n",
    "        tokenizedA = np.concatenate(tokenizedA, axis=0, out=None, dtype=None, casting=\"same_kind\")\n",
    "\n",
    "    return tokenizedA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75583f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я хочу поступить к вам на психологию? - Текст основного вопроса\n",
      "поступление - перевод - ИИ класс\n",
      "[36349.   877.] - Токенизированный текст основного вопроса\n",
      "100.0 % - Процент сходства с найденным вопросом\n",
      "4195 - Номер найденного вопроса\n",
      "здравствуйте! я хочу поступить к вам на заочное отделение на учёбу, бакалавриат специальность: Менеджмент в туристской и гостиничной индустрии. - Текст найденного вопроса\n",
      "[36349.0, 877.0] - Токенизированный найденный вопрос\n",
      "Здравствуйте. Отлично. Рекомендуем начать с изучения Правил приема в ВУЗ на 2020 год. - Ответ к найденному вопросу\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pre_trained_model_ckpt)\n",
    "class_names = ['поступление - перевод', 'общежитие', 'учебная деятельность', 'внеучебная деятельность', 'документы', 'работа', 'финансы']\n",
    "myModel = SentimentClassifier(len(class_names))\n",
    "myModel.load_state_dict(torch.load('model/best_model_state.bin'))\n",
    "myModel = myModel.to(device)\n",
    "\n",
    "text = \"Я хочу поступить к вам на психологию?\"\n",
    "encoded_review = tokenizer.encode_plus(text, max_length=512, add_special_tokens=True, return_token_type_ids=False, pad_to_max_length=True, return_attention_mask=True,\n",
    "                                       truncation=True, return_tensors='pt')\n",
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask=encoded_review['attention_mask'].to(device)\n",
    "output = myModel(input_ids, attention_mask)\n",
    "_,prediction = torch.max(output, dim=1)\n",
    "\n",
    "tToken = tokenText(text)\n",
    "tq = []\n",
    "index = 0\n",
    "probability = 0.00\n",
    "textQ = ''\n",
    "textA = ''\n",
    "questions = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    if (probability <= mySort(tToken, eval(df['tq'][i])) and df['label'][i] == int(prediction)):\n",
    "        tq = eval(df['tq'][i])\n",
    "        index = i\n",
    "        textQ = df['q'][i]\n",
    "        textA = df['a'][i]\n",
    "        probability = mySort(tToken, eval(df['tq'][i]))\n",
    "        questions.append([tq, index, textQ, textA, probability])\n",
    "\n",
    "max_last_elem = max([que[-1] for que in questions])\n",
    "max_lists = [lst for lst in questions if lst[-1] == max_last_elem]\n",
    "rand = random.choice(max_lists)\n",
    "\n",
    "print(text, '- Текст основного вопроса')\n",
    "print(class_names[prediction], '- ИИ класс')\n",
    "print(tToken, '- Токенизированный текст основного вопроса')\n",
    "\n",
    "print(rand[4]*100, '% - Процент сходства с найденным вопросом')\n",
    "print(rand[1], '- Номер найденного вопроса')\n",
    "print(rand[2], '- Текст найденного вопроса')\n",
    "print(rand[0], '- Токенизированный найденный вопрос')\n",
    "print(rand[3], '- Ответ к найденному вопросу')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093995df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc1786a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
